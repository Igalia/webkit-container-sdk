#!/usr/bin/env bash

[ -f "${WKDEV_SDK}/.wkdev-sdk-root" ] && source "${WKDEV_SDK}/utilities/application.sh" || { echo "Please set \${WKDEV_SDK} to point to the root of the wkdev-sdk checkout."; exit 1; }
init_application "${0}" "Create a new container ready to use for WebKit GTK/WPE development." host-only

# Source utility script fragments
source "${WKDEV_SDK}/utilities/cpu-profiling.sh"
source "${WKDEV_SDK}/utilities/host-setup-tasks.sh"
source "${WKDEV_SDK}/utilities/nvidia-gpu.sh"
source "${WKDEV_SDK}/utilities/podman.sh"

argsparse_use_option debug        "Enable debug logging for podman (useful to debug container issues)"
argsparse_use_option trace        "Enable 'xtrace' mode for this script"
argsparse_use_option =verbose     "Increase verbosity of this script"

argsparse_use_option =user:       "Container account user name" type:username default:$(id --user --name)
argsparse_use_option =group:      "Container account group name" type:group default:$(id --group --name)
argsparse_use_option =shell:      "Specific shell to use for interactive container usage" type:file default:${SHELL}
argsparse_use_option =create-home "Create home directory and add necessary configuration files (shell settings, etc.)"
argsparse_use_option shared-dir:  "Path to existing or to-be-created shared directory that will map to the same path on the host"
argsparse_use_option h=ome:       "Path to existing or to-be-created container home directory" default:${HOME}/wkdev-home
argsparse_use_option =name:       "Name of container" default:wkdev
argsparse_use_option rm           "Force removal of container if it already exists."
argsparse_use_option attach       "Attach to container as it starts up."

argsparse_usage_description="$(cat <<EOF
<< Purpose >>

    Creates & starts a new podman container that runs the '$(get_sdk_image_name)' image with approriate settings.

    The Podman containers run *unprivileged* and *rootless* -- as hardened as possible, while still
    offering tight integration with the host. The host system shares the systemd, d-bus, X11, wayland,
    PulseAudio, ... sockets via bind-mounts with the container, allowing for smooth integration of
    applications started from within the container with the host users' running desktop session.

<< Examples >>

    $ ${application_name} --create-home --home \${HOME}/wkdev-home --name wkdev
    $ ${application_name} --home \${HOME}/wkdev-home --trace --name wkdev2
    $ ${application_name} --home \${HOME}/wkdev-home --debug --shell /usr/bin/bash --name wkdev3
    $ ${application_name} --home \${HOME}/wkdev-home --shared-dir \${HOME}/wkdev-shared
EOF
)"

# Hardcoded settings
get_settings_table_first_column_size() { echo 40; }
get_settings_table_second_column_size() { echo 40; }
get_settings_table_print_prefix() { echo "         "; }

process_command_line_arguments() {

    argsparse_allow_no_argument "true"
    argsparse_parse_options "${@}"
    argsparse_is_option_set "trace" && set -o xtrace

    container_shell="${program_options["shell"]}"
    container_name="${program_options["name"]}"
    container_user_home="${program_options["home"]}"

    container_user_name="${program_options["user"]}"
    container_user_id=$(id --user --real "${container_user_name}")

    host_user_name=$(id --user --name)
    host_user_id=$(id --user --real)

    host_group_name=$(id --group --name)
    host_group_id=$(id --group --real)

    container_group_name="${program_options["group"]}"
    container_group_id=$(id --group --real "${container_group_name}")

    host_hostname="$(hostnamectl hostname)"
    container_hostname="$(basename "${container_name}").${host_hostname}"

    # Verify the container home directory is accessible.
    if [ ! -d "${container_user_home}" ]; then
        if ! argsparse_is_option_set "create-home"; then
            _abort_ "The passed home directory '${container_user_home}' does not exist (pass --create-home, if you want to automatically create them)"
        else
            echo ""
            echo "-> The passed home directory '${container_user_home}' does not exist, creating..."
            echo ""

            # Copy shell configuration skeleton files from host.
            cp --recursive --verbose /etc/skel "${container_user_home}"

            # Set ownership / permissions
            chown ${container_user_id}:${container_group_id} "${container_user_home}"
            chmod 750 "${container_user_home}"

            default_config_directory="$(get_container_home_defaults_directory_name)"
            shell_type=$(basename "${SHELL}")
            mkdir --parents "${container_user_home}"/.config
            if [ "${shell_type}" = "bash" ]; then
                cp --verbose "${default_config_directory}"/dot-bash_login "${container_user_home}"/.bash_login
                cp --verbose "${default_config_directory}"/dot-bash_profile "${container_user_home}"/.bash_profile
            elif [ "${shell_type}" = "zsh" ]; then
                cp --verbose "${default_config_directory}"/dot-zlogin "${container_user_home}"/.zlogin
                cp --verbose "${default_config_directory}"/dot-zprofile "${container_user_home}"/.zprofile
                cp --verbose "${default_config_directory}"/dot-zshrc "${container_user_home}"/.zshrc
            elif [ "${shell_type}" = "fish" ]; then
                mkdir "${container_user_home}"/.config/fish
                cp --verbose "${default_config_directory}"/fish-config "${container_user_home}"/.config/fish/config.fish
            else
                echo ""
                echo "-> Shell '${shell_type}' auto configuration is unsupported. Please setup the configuration files for your shell " \
                     "on your own (see $(get_container_home_defaults_directory_name)/dot-* to examine the default settings for other shells."
            fi

            cp --verbose "${default_config_directory}"/dot-gdbinit "${container_user_home}"/.gdbinit
            cp --verbose "${default_config_directory}"/dot-aptly.conf "${container_user_home}"/.aptly.conf

            echo ""
        fi
    else
        echo ""
        echo "-> The passed home directory '${container_user_home}' already exists. Skipping configuration."
        echo ""
    fi

    # Verify we should setup a shared folder and it's accessible
    if argsparse_is_option_set "shared-dir"; then
        container_shared_folder="${program_options["shared-dir"]}"
        # Normalize relative paths so we can bind mount them
        if [ "${container_shared_folder#/*}" == "$container_shared_folder" ]; then
            container_shared_folder=$(realpath "$container_shared_folder")
        fi

        if [ ! -d "${container_shared_folder}" ]; then
            echo "-> Shared folder '${container_shared_folder}' does not exist, creating."
            echo ""
            mkdir --parents "${container_shared_folder}"
        else
            echo "-> Setting up '${container_shared_folder}' as shared folder between host and container"
            echo ""
        fi
    else
        echo "-> Not setting shared folder."
        echo ""
    fi
    # Stop & remove existing container if '--rm' is given.
    if argsparse_is_option_set "rm"; then
        run_podman_silent stop "${container_name}"
        run_podman_silent rm "${container_name}"
    fi
}

try_process() {

    local -n arguments=${1}
    local operation="${2}"
    local test_condition=${3}
    shift 3

    local -a key_value_pair=(${@})
    if [ ${test_condition} -eq 1 ]; then
        echo "     [x] ${operation}"
        arguments+=(${key_value_pair[@]})
    else
        echo "     [ ] ${operation}"
    fi
}

try_process_user() {

    # Map host UID/GIDs into container user namespace, unmodified!
    # The 'keep-id' mode for user namespaces is mandatory, when the container shall
    # be able to communicate with the host dbus session, while staying unprivileged.
    # Reference: https://github.com/containers/podman/discussions/16772
    local podman_argument=("--userns" "keep-id")

    # root inside the container is mapped to the current host user. We need root access
    # only for the initial bootstrapping (executing wkdev-init).
    podman_argument+=("--user" "root:root")

    try_process ${1} "Map host user UID/GID unmodified into user namespace" 1 ${podman_argument[@]}
}

try_process_groups() {

    # Map secondary GIDS into container user namespace as well.
    local podman_argument=("--group-add" "keep-groups")
    try_process ${1} "Map host user secondary GIDs into user namespace" 1 ${podman_argument[@]}
}

try_process_home_directory() {

    # Map given home directory path as container user home directory (eventually separated from host home directory).
    local podman_argument=("--env" "HOST_HOME=/host/home/${container_user_name}")
    podman_argument+=("--env" "HOST_CONTAINER_HOME_PATH=${container_user_home}")
    podman_argument+=("--mount" "type=bind,source=${container_user_home},destination=/home/${container_user_name},rslave")
    podman_argument+=("--mount" "type=bind,source=${HOME},destination=/host/home/${container_user_name},rslave")

    # systemctl --user is-enabled <some-service> relies on the accessibility of ~/.config/systemd/user, map it into the container if available.
    [ -d "${HOME}/.config/systemd/user" ] && podman_argument+=("--mount" "type=bind,source=${HOME}/.config/systemd/user,destination=/home/${container_user_name}/.config/systemd/user,rslave")

    try_process ${1} "Expose both host & container home directory" 1 ${podman_argument[@]}
}

try_process_shared_directory() {
    local shared_directory_wanted=$(argsparse_is_option_set "shared-dir" && echo 1 || echo 0)
    local podman_argument=("--mount" "type=bind,source=${container_shared_folder},destination=${container_shared_folder},rslave")
    try_process ${1} "Expose common shared directory (optional)" ${shared_directory_wanted} ${podman_argument[@]}
}

try_process_coredump_directory() {

    # coredumpctl needs to share the directory when the systemd service stores the coredumps
    local coredump_directory="/var/lib/systemd/coredump"
    local podman_argument=("--mount" "type=bind,source=${coredump_directory},destination=${coredump_directory},rslave")
    local coredump_directory_exists=$([ -d "${coredump_directory}" ] && echo 1 || echo 0)
    try_process ${1} "Expose systemd-coredump directory in case it is present" ${coredump_directory_exists} ${podman_argument[@]}
}

try_process_timezone() {

    local podman_argument=("--tz" "local")
    try_process ${1} "Share host timezone settings with container" 1 ${podman_argument[@]}
}

try_process_ulimit() {

    local podman_argument=("--ulimit" "host")
    try_process ${1} "Share host ulimit settings with container" 1 ${podman_argument[@]}
}

try_process_journal() {

    local journal_directory="/var/log/journal"
    local journal_directory_exists=$([ -d "${journal_directory}" ] && echo 1 || echo 0)
    local podman_argument=("--mount" "type=bind,source=${journal_directory},destination=${journal_directory},ro,rslave")
    try_process ${1} "Share system journal with container (read-only)" ${journal_directory_exists} ${podman_argument[@]}
}

try_process_keyring() {

    local keyring_directory="${XDG_RUNTIME_DIR}/keyring"
    local keyring_directory_exists=$([ -d "${keyring_directory}" ] && echo 1 || echo 0)
    local podman_argument=("--mount" "type=bind,source=${keyring_directory},destination=${keyring_directory},rslave")
    podman_argument+=("--env" "SSH_AUTH_SOCK=${keyring_directory}/ssh")
    try_process ${1} "Share keyring with container" ${keyring_directory_exists} ${podman_argument[@]}
}

try_process_dbus_user_session() {

    local dbus_user_socket="${XDG_RUNTIME_DIR}/bus"
    local dbus_user_socket_exists=$([ -S "${dbus_user_socket}" ] && echo 1 || echo 0)
    local podman_argument=("--mount" "type=bind,source=${dbus_user_socket},destination=${dbus_user_socket},rslave")
    podman_argument+=("--env" "DBUS_SESSION_BUS_ADDRESS=unix:path=${dbus_user_socket}")
    try_process ${1} "Share dbus user session with container" ${dbus_user_socket_exists} ${podman_argument[@]}
}

try_process_dconf() {

    local dconf_directory="${XDG_RUNTIME_DIR}/dconf"
    local dconf_directory_exists=$([ -d "${dconf_directory}" ] && echo 1 || echo 0)
    local podman_argument=("--mount" "type=bind,source=${dconf_directory},destination=${dconf_directory},rslave")
    try_process ${1} "Share dconf settings with container" ${dconf_directory_exists} ${podman_argument[@]}
}

try_process_accessibility() {

    local at_spi_directory="${XDG_RUNTIME_DIR}/at-spi"
    local at_spi_directory_exists=$([ -d "${at_spi_directory}" ] && echo 1 || echo 0)
    local podman_argument=("--mount" "type=bind,source=${at_spi_directory},destination=${at_spi_directory},rslave")
    try_process ${1} "Share accessibility bus with container" ${at_spi_directory_exists} ${podman_argument[@]}
}

try_process_themes() {

    local themes_directory_exists=$([ -d "/usr/share/themes" ] && echo 1 || echo 0)
    local podman_argument=("--mount" "type=bind,source=/usr/share/themes,destination=/usr/local/share/themes,rslave")
    try_process ${1} "Share host themes with container" ${themes_directory_exists} ${podman_argument[@]}
}

try_process_icons() {

    local icons_directory_exists=$([ -d "/usr/share/icons" ] && echo 1 || echo 0)
    local podman_argument=("--mount" "type=bind,source=/usr/share/icons,destination=/usr/local/share/icons,rslave")
    try_process ${1} "Share host icons with container" ${icons_directory_exists} ${podman_argument[@]}
}

try_process_fonts() {

    local fonts_directory_exists=$([ -d "/usr/share/fonts" ] && echo 1 || echo 0)
    local podman_argument=("--mount" "type=bind,source=/usr/share/fonts,destination=/usr/local/share/fonts,rslave")
    try_process ${1} "Share host fonts with container" ${fonts_directory_exists} ${podman_argument[@]}
}

try_process_dri() {

    local is_dri_device_available=$([ -d "/dev/dri" ] && echo 1 || echo 0)
    local podman_argument=("--device" "/dev/dri")
    try_process ${1} "Access to host DRI devices" ${is_dri_device_available} ${podman_argument[@]}
}

try_process_nvidia_gpu() {

    local is_nvidia_gpu_available=$(is_nvidia_gpu_installed && [ -f "$(get_nvidia_cdi_config_file)" ] && echo 1 || echo 0)
    local podman_argument=("--device" "nvidia.com/gpu=all")
    try_process ${1} "Access to NVIDIA GPU on host" ${is_nvidia_gpu_available} ${podman_argument[@]}
}

try_process_wayland() {

    local wayland_socket="${XDG_RUNTIME_DIR}/${WAYLAND_DISPLAY}"
    local wayland_socket_exists=$([ -S "${wayland_socket}" ] && echo 1 || echo 0)
    local podman_argument=("--env" "WAYLAND_DISPLAY=${WAYLAND_DISPLAY}")
    podman_argument+=("--env" "XDG_RUNTIME_DIR=${XDG_RUNTIME_DIR}")
    podman_argument+=("--env" "XDG_SESSION_TYPE=${XDG_SESSION_TYPE}")
    podman_argument+=("--mount" "type=bind,source=${wayland_socket},destination=${wayland_socket},rslave")
    try_process ${1} "Access to Wayland on host" ${wayland_socket_exists} ${podman_argument[@]}
}

try_process_x11() {

    local is_x11_display_set=$([ -z "${DISPLAY}" ] && echo 0 || echo 1)
    local podman_argument=("--env" "DISPLAY=${DISPLAY}")
    podman_argument+=("--mount" "type=bind,source=/tmp/.X11-unix,destination=/tmp/.X11-unix,rslave")
    try_process ${1} "Access to X11 on host" ${is_x11_display_set} ${podman_argument[@]}
}

try_process_pulseaudio() {

    local pulseaudio_directory="${XDG_RUNTIME_DIR}/pulse"
    local pulseaudio_directory_exists=$([ -d "${pulseaudio_directory}" ] && echo 1 || echo 0)
    local podman_argument=("--mount" "type=bind,source=${pulseaudio_directory},destination=${pulseaudio_directory},rslave")
    podman_argument+=("--mount" "type=bind,source=/etc/machine-id,destination=/etc/machine-id,ro,rslave")
    try_process ${1} "Access to PulseAudio on host" ${pulseaudio_directory_exists} ${podman_argument[@]}
}

try_process_podman() {

    local podman_socket="${XDG_RUNTIME_DIR}/podman/podman.sock"
    local podman_socket_exists=$([ -S "${podman_socket}" ] && echo 1 || echo 0)
    local podman_argument=("--env" "HOST_PODMAN_SOCKET=${podman_socket}.host")
    podman_argument+=("--mount" "type=bind,source=${podman_socket},destination=${podman_socket}.host,rslave")
    try_process ${1} "Access to Podman on host" ${podman_socket_exists} ${podman_argument[@]}
}

build_podman_create_arguments() {

    local -n arguments=${1}

    # NOTE: Extra capabilities are needed to run podman in podman. We don't need it,
    # since we command the host podman to run extra containers for us, when needed.

    # Map our SDK git repository into the container.
    arguments+=("--mount" "type=bind,source=${WKDEV_SDK},destination=/wkdev-sdk,rslave")

    # Add 'SYS_PTRACE' support, to be able to use gdb.
    arguments+=("--cap-add=SYS_PTRACE")

    # Add 'NET_RAW' support, to be able to use ping
    arguments+=("--cap-add=NET_RAW")

    # Add 'SYS_ADMIN' support, to be able to use CPU profiiling.
    arguments+=("--cap-add=SYS_ADMIN")

    # Set container name & hostname & workdir.
    arguments+=("--name" "${container_name}")
    arguments+=("--hostname" "${container_hostname}")
    arguments+=("--workdir" "/home/${container_user_name}")

    # Share pid namepace with host -- otherwise 'systemctl --user' won't work.
    #
    # Long story:
    # PID 1 is assumed to be the systemd "system session" and systemctl communicates
    # with PID 1 via dbus. Therefore one either has to provide a session within the
    # container (use systemd init mechanism) or share the PID namespace with the host,
    # and let 'systemctl --user' communicate with the host PID 1 (require systemd host).
    arguments+=("--pid" "host")

    # Share IPC namepace with host -- otherwise /dev/shm access (e.g. in glxgears) won't work.
    arguments+=("--ipc" "host")

    # Share network namepace with host.
    arguments+=("--network" "host")

    # Map /etc/{hosts|localtime|resolv.conf} into container.
    arguments+=("--mount" "type=bind,source=/etc/hosts,destination=/etc/hosts,ro")
    arguments+=("--mount" "type=bind,source=/etc/localtime,destination=/etc/localtime,ro")
    arguments+=("--mount" "type=bind,source=/etc/resolv.conf,destination=/etc/resolv.conf,ro")

    # Mount /dev/pts in container (pseudo-terminal support).
    arguments+=("--mount" "type=devpts,destination=/dev/pts")

    # Disable SELinux isolation.
    arguments+=("--security-opt label=disable")

    # Allow for unprivileged user namespaces (bwrap) to work.
    arguments+=("--security-opt unmask=ALL")

    # Required for rr to work.
    arguments+=("--security-opt seccomp=unconfined")

    set +o nounset
    try_process_user ${1}
    try_process_groups ${1}
    try_process_home_directory ${1}
    try_process_shared_directory ${1}
    try_process_coredump_directory ${1}
    try_process_timezone ${1}
    try_process_ulimit ${1}
    try_process_journal ${1}
    try_process_keyring ${1}
    try_process_dbus_user_session ${1}
    try_process_dconf ${1}
    try_process_accessibility ${1}
    try_process_themes ${1}
    try_process_icons ${1}
    try_process_fonts ${1}
    try_process_dri ${1}
    try_process_nvidia_gpu ${1}
    try_process_wayland ${1}
    try_process_x11 ${1}
    try_process_pulseaudio ${1}
    try_process_podman ${1}
    set -o nounset

    arguments+=("$(get_sdk_qualified_name_and_tag)")

    # Entry point
    arguments+=("/wkdev-sdk/scripts/container-only/wkdev-init")
    arguments+=("--shell" "${container_shell}")
    arguments+=("--user" "${container_user_name}")
    arguments+=("--group" "${container_group_name}")

    if argsparse_is_option_set "attach"; then
        arguments+=("--exit-when-done")
    fi
}

build_podman_arguments() {

    local -n generic_arguments=${1}

    argsparse_is_option_set "debug" && generic_arguments+=("--log-level debug")
}

# Pretty printing tables
print_table_header_border() {

    printf "+%$(expr $(get_settings_table_first_column_size) + 2)s+%$(expr $(get_settings_table_second_column_size) + 2)s+" | tr " " "-"
}

print_table_header() {

    local column_title_1="${1}"
    local column_title_2="${2}"
    printf "| %-$(get_settings_table_first_column_size)s | %-$(get_settings_table_second_column_size)s |\n" "${column_title_1}" "${column_title_2}"
}

print_table_row() {

    local key="${1}"
    local value="${2}"
    printf "| %-$(get_settings_table_first_column_size)s | %-$(get_settings_table_second_column_size)s |\n" "${key}" "${value}"
}

print_table() {

    printf "%s%s\n" "$(get_settings_table_print_prefix)" "${1}"
}

print_host_settings() {

    echo ""
    echo "     Host settings:"
    echo ""

    print_table "$(print_table_header_border)"
    print_table "$(print_table_header "Key" "Value")"
    print_table "$(print_table_header_border)"
    print_table "$(print_table_row "Hostname" "${host_hostname}")"
    print_table "$(print_table_row "User name" "$(printf "%s %s" "${host_user_name}" "(UID ${host_user_id})")")"
    print_table "$(print_table_row "Group name" "$(printf "%s %s" "${host_group_name}" "(GID ${host_group_id})")")"
    print_table "$(print_table_row "\${XDG_RUNTIME_DIR}" "${XDG_RUNTIME_DIR-}")"
    print_table "$(print_table_row "\${XDG_SESSION_TYPE}" "${XDG_SESSION_TYPE-}")"
    print_table "$(print_table_row "\${WAYLAND_DISPLAY}" "${WAYLAND_DISPLAY-}")"
    print_table "$(print_table_row "\${DISPLAY}" "${DISPLAY-}")"
    print_table "$(print_table_row "$(get_perf_event_procfs_path)" "$(read_kernel_parameter "$(get_perf_event_kernel_setting)")")"

    # Do not attempt to validate the /etc/sub?id files for printing purposes, assume no duplicates are present and
    # an entry is present for the current UID or the current user name, but not both.
    subuid_settings="MISSING!"
    subuid_name_entries=$(cat /etc/subuid | grep "${host_user_name}")
    if [ ! -z "${subuid_name_entries}" ]; then
        subuid_settings=$(echo "${subuid_name_entries}" | awk -F':' '{ print $3 " UIDs available, first: " $2 }')
    else
        subuid_id_entries=$(cat /etc/subuid | grep "${host_user_id}")
        subuid_settings=$(echo "${subuid_id_entries}" | awk -F':' '{ print $3 " UIDs available, first: " $2 }')
    fi

    subgid_settings="MISSING!"
    subgid_name_entries=$(cat /etc/subgid | grep "${host_group_name}")
    if [ ! -z "${subgid_name_entries}" ]; then
        subgid_settings=$(echo "${subgid_name_entries}" | awk -F':' '{ print $3 " GIDs available, first: " $2 }')
    else
        subgid_id_entries=$(cat /etc/subgid | grep "${host_group_id}")
        subgid_settings=$(echo "${subgid_id_entries}" | awk -F':' '{ print $3 " GIDs available, first: " $2 }')
    fi

    print_table "$(print_table_row "/etc/subuid" "${subuid_settings}")"
    print_table "$(print_table_row "/etc/subgid" "${subgid_settings}")"
    print_table "$(print_table_header_border)"
}

print_container_settings() {

    echo ""
    echo "     Container settings:"
    echo ""

    print_table "$(print_table_header_border)"
    print_table "$(print_table_header "Key" "Value")"
    print_table "$(print_table_header_border)"
    print_table "$(print_table_row "Hostname" "${container_hostname}")"
    print_table "$(print_table_row "User name" "$(printf "%s %s" "${container_user_name}" "(UID ${container_user_id})")")"
    print_table "$(print_table_row "Group name" "$(printf "%s %s" "${container_group_name}" "(UID ${container_group_id})")")"
    print_table "$(print_table_header_border)"
}

print_user_namespace_settings() {

    echo ""
    echo "     Host -> Container UID/GID mapping configuration for rootless mode:"
    echo ""

    echo "         $ podman unshare cat /proc/self/uid_map:"
    podman unshare cat /proc/self/uid_map
    echo ""

    echo "         $ podman unshare cat /proc/self/gid_map:"
    podman unshare cat /proc/self/gid_map
    echo ""

    echo "         The '/proc/self/{uid|gid}_map' contains N rows with triplets, that describe a mapping of UIDs/GIDs"
    echo "         \"<host-id> <container-id> <count>\" ---> [<container-id>, ..., <container-id> + <count>]."
}

print_settings() {

    print_host_settings
    print_container_settings
    print_user_namespace_settings
}

try_enable_lingering_on_host() {

    echo ""

    local linger_status=$(loginctl show-user "${host_user_name}" | grep Linger | sed -e s/Linger=//)
    if [ "${linger_status}" = "no" ]; then
        echo "-> Enable lingering for user '${host_user_name}' on host system..."
        loginctl enable-linger ${host_user_name}
    else
        echo "-> Lingering for user '${host_user_name}' is already activated."
    fi
}

try_enable_user_podman_socket_service_on_host() {

    echo ""

    local service="podman.socket"
    local socket_status=$(systemctl --user is-enabled "${service}")
    if [ "${socket_status}" = "disabled" ]; then
        echo "-> Enable '${service}' systemd user service for user '${host_user_name}' on host system..."
        systemctl --user enable "${service}"
        systemctl --user start "${service}"
    else
        echo "-> The systemd user service '${service}' is already enabled."
    fi

    if argsparse_is_option_set "verbose"; then
        echo ""
        echo "systemctl --user status ${service}:"
        systemctl --user status "${service}"
    fi
}

try_enable_nvidia_container_integration_on_host() {

    echo ""

    if [ ! -f "$(get_nvidia_cdi_config_file)" ]; then
        echo "-> Enable NVIDIA GPU container integration on host system, running 'wkdev-setup-nvidia-gpu-for-container'..."
        # Continue gracefully, as long as the setup script is not widely tested.
        "${WKDEV_SDK}/scripts/host-only/wkdev-setup-nvidia-gpu-for-container" || _log_ "Script failed, please investigate."
    else
        echo "-> The NVIDIA GPU container integration is already enabled on host system."
    fi
}

try_enable_nvidia_gpu_profiling_settings_on_host() {

    echo ""

    if [ -f "$(get_nvidia_gpu_profiling_conf_file)" ]; then
        echo "-> The NVIDIA kernel module settings were already deployed to $(get_nvidia_gpu_profiling_conf_file) - no need to modify."
    else
        echo "-> Deploying NVIDIA kernel module settings to $(get_nvidia_gpu_profiling_conf_file)..."
        echo 'options nvidia "NVreg_RestrictProfilingToAdminUsers=0"' | sudo tee "$(get_nvidia_gpu_profiling_conf_file)" &>/dev/null

        echo "-> Updating /boot/initrd.img files..."
        if does_executable_exist dracut; then
            sudo dracut --regenerate-all --force
        elif does_executable_exist update-initramfs; then
            update-initramfs -u -k all
        else
            _abort_ "Cannot update initram - which method to use?"
        fi

        echo ""
        echo "NOTE: YOU NEED TO REBOOT THE HOST SYSTEM ONCE!"
    fi
}

# Main functionality
run() {

    process_command_line_arguments "${@}"

    echo "-> Preparing creation of rootless podman container..."
    print_settings

    try_enable_lingering_on_host
    try_enable_user_podman_socket_service_on_host

    if is_nvidia_gpu_installed; then
        try_enable_nvidia_container_integration_on_host
        try_enable_nvidia_gpu_profiling_settings_on_host
    fi

    host_setup_prerun_tasks

    echo ""
    echo "-> Host integration features:"
    echo ""

    local podman_create_arguments=()
    build_podman_create_arguments podman_create_arguments

    local podman_arguments=()
    build_podman_arguments podman_arguments

    run_podman_login

    echo ""
    echo "-> Creating container '${container_name}'..."
    if argsparse_is_option_set "verbose"; then
        echo ""
        echo "     $ podman ${podman_arguments[@]} create ${podman_create_arguments[@]}"
    fi

    container_id=$(run_podman ${podman_arguments[@]} create ${podman_create_arguments[@]})
    [ -z "${container_id}" ] && _abort_ "Container creation failed - please check the logs and report any issue"

    echo ""
    echo "-> Starting container '${container_name}'..."

    if argsparse_is_option_set "attach"; then
        run_podman_silent_unless_verbose start --attach "${container_id}"
    else
        echo "   NOTE: Use \`podman logs -f ${container_name}\` to follow the initialization."
        run_podman_silent start "${container_id}"
    fi

    echo ""
    echo "-> Finished creation of container '${container_name}'!"
    echo "   NOTE: Use \`wkdev-enter --name ${container_name}\` to launch an interactive shell."
}

run "${@}"
